{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: /physical_device:GPU:0   Type: GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)\n",
    "\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/cowper.txt\n",
      "819200/815980 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/derby.txt\n",
      "811008/809730 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/butler.txt\n",
      "811008/807992 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sunlin\\\\.keras\\\\datasets'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIRECTORY_URL = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n",
    "FILE_NAMES = ['cowper.txt', 'derby.txt', 'butler.txt']\n",
    "\n",
    "for name in FILE_NAMES:\n",
    "  text_dir = tf.keras.utils.get_file(name, origin=DIRECTORY_URL+name)\n",
    "  \n",
    "parent_dir = os.path.dirname(text_dir)\n",
    "\n",
    "parent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeler(example, index):\n",
    "  return example, tf.cast(index, tf.int64)  \n",
    "\n",
    "labeled_data_sets = []\n",
    "\n",
    "for i, file_name in enumerate(FILE_NAMES):\n",
    "  lines_dataset = tf.data.TextLineDataset(os.path.join(parent_dir, file_name))\n",
    "  labeled_dataset = lines_dataset.map(lambda ex: labeler(ex, i))\n",
    "  labeled_data_sets.append(labeled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 64\n",
    "TAKE_SIZE = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labeled_data = labeled_data_sets[0]\n",
    "for labeled_dataset in labeled_data_sets[1:]:\n",
    "  all_labeled_data = all_labeled_data.concatenate(labeled_dataset)\n",
    "  \n",
    "all_labeled_data = all_labeled_data.shuffle(\n",
    "    BUFFER_SIZE, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=74, shape=(), dtype=string, numpy=b'While, every Grecian heart he tamed, and took'>, <tf.Tensor: id=75, shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: id=76, shape=(), dtype=string, numpy=b'that led off at the start must have been disabled out on the plain. I'>, <tf.Tensor: id=77, shape=(), dtype=int64, numpy=2>)\n",
      "(<tf.Tensor: id=78, shape=(), dtype=string, numpy=b\"From slaughter'd Trojans, after Ocean's God\">, <tf.Tensor: id=79, shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: id=80, shape=(), dtype=string, numpy=b'Around, a darksome trench; beyond, a fence'>, <tf.Tensor: id=81, shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: id=82, shape=(), dtype=string, numpy=b'of fleet Acamas chief of the Thracians. \"Sons of Priam,\" said he, \"how'>, <tf.Tensor: id=83, shape=(), dtype=int64, numpy=2>)\n"
     ]
    }
   ],
   "source": [
    "for ex in all_labeled_data.take(5):\n",
    "  print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17178"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "vocabulary_set = set()\n",
    "for text_tensor, _ in all_labeled_data:\n",
    "  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
    "  vocabulary_set.update(some_tokens)\n",
    "\n",
    "vocab_size = len(vocabulary_set)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'While, every Grecian heart he tamed, and took'\n"
     ]
    }
   ],
   "source": [
    "example_text = next(iter(all_labeled_data))[0].numpy()\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2976, 5831, 724, 3308, 11976, 6430, 12047, 15273]\n"
     ]
    }
   ],
   "source": [
    "encoded_example = encoder.encode(example_text)\n",
    "print(encoded_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text_tensor, label):\n",
    "  encoded_text = encoder.encode(text_tensor.numpy())\n",
    "  return encoded_text, label\n",
    "\n",
    "def encode_map_fn(text, label):\n",
    "  return tf.py_function(encode, inp=[text, label], Tout=(tf.int64, tf.int64))\n",
    "\n",
    "all_encoded_data = all_labeled_data.map(encode_map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\n",
    "train_data = train_data.padded_batch(BATCH_SIZE, padded_shapes=([-1],[]))\n",
    "\n",
    "test_data = all_encoded_data.take(TAKE_SIZE)\n",
    "test_data = test_data.padded_batch(BATCH_SIZE, padded_shapes=([-1],[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=99547, shape=(16,), dtype=int64, numpy=\n",
       " array([ 2976,  5831,   724,  3308, 11976,  6430, 12047, 15273,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0], dtype=int64)>,\n",
       " <tf.Tensor: id=99551, shape=(), dtype=int64, numpy=0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text, sample_labels = next(iter(test_data))\n",
    "\n",
    "sample_text[0], sample_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Embedding(vocab_size, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One or more dense layers.\n",
    "# Edit the list in the `for` line to experiment with layer sizes.\n",
    "for units in [64, 64]:\n",
    "  model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "\n",
    "# Output layer. The first argument is the number of labels.\n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "697/697 [==============================].0969 - accuracy: 0.37 - 21s 10s/step - loss: 1.0937 - accuracy: 0.38 - 21s 7s/step - loss: 1.0891 - accuracy: 0.3906 - 21s 5s/step - loss: 1.0855 - accuracy: 0.398 - 21s 4s/step - loss: 1.0802 - accuracy: 0.412 - 21s 3s/step - loss: 1.0777 - accuracy: 0.398 - 21s 3s/step - loss: 1.0762 - accuracy: 0.399 - 21s 3s/step - loss: 1.0733 - accuracy: 0.398 - 21s 2s/step - loss: 1.0694 - accuracy: 0.404 - 21s 2s/step - loss: 1.0647 - accuracy: 0.406 - 21s 2s/step - loss: 1.0630 - accuracy: 0.416 - 21s 2s/step - loss: 1.0579 - accuracy: 0.415 - 21s 2s/step - loss: 1.0546 - accuracy: 0.413 - 21s 2s/step - loss: 1.0516 - accuracy: 0.406 - 21s 1s/step - loss: 1.0487 - accuracy: 0.402 - 21s 1s/step - loss: 1.0441 - accuracy: 0.401 - 21s 1s/step - loss: 1.0393 - accuracy: 0.400 - 21s 1s/step - loss: 1.0350 - accuracy: 0.401 - 21s 1s/step - loss: 1.0297 - accuracy: 0.404 - 21s 1s/step - loss: 1.0226 - accuracy: 0.417 - 21s 1s/step - loss: 1.0185 - accuracy: 0.421 - 21s 967ms/step - loss: 1.0146 - accuracy: 0.42 - 21s 926ms/step - loss: 1.0084 - accuracy: 0.43 - 21s 889ms/step - loss: 1.0008 - accuracy: 0.43 - 21s 854ms/step - loss: 0.9948 - accuracy: 0.44 - 21s 822ms/step - loss: 0.9892 - accuracy: 0.45 - 21s 792ms/step - loss: 0.9865 - accuracy: 0.45 - 21s 764ms/step - loss: 0.9797 - accuracy: 0.45 - 21s 739ms/step - loss: 0.9743 - accuracy: 0.46 - 21s 715ms/step - loss: 0.9670 - accuracy: 0.46 - 21s 692ms/step - loss: 0.9640 - accuracy: 0.46 - 21s 671ms/step - loss: 0.9627 - accuracy: 0.46 - 22s 652ms/step - loss: 0.9557 - accuracy: 0.47 - 22s 633ms/step - loss: 0.9492 - accuracy: 0.47 - 22s 616ms/step - loss: 0.9429 - accuracy: 0.48 - 22s 599ms/step - loss: 0.9353 - accuracy: 0.48 - 22s 583ms/step - loss: 0.9324 - accuracy: 0.48 - 22s 569ms/step - loss: 0.9308 - accuracy: 0.48 - 22s 555ms/step - loss: 0.9225 - accuracy: 0.49 - 22s 541ms/step - loss: 0.9221 - accuracy: 0.49 - 22s 528ms/step - loss: 0.9169 - accuracy: 0.49 - 22s 516ms/step - loss: 0.9160 - accuracy: 0.49 - 22s 505ms/step - loss: 0.9197 - accuracy: 0.50 - 22s 494ms/step - loss: 0.9134 - accuracy: 0.50 - 22s 483ms/step - loss: 0.9086 - accuracy: 0.50 - 22s 473ms/step - loss: 0.9027 - accuracy: 0.50 - 22s 463ms/step - loss: 0.8984 - accuracy: 0.51 - 22s 454ms/step - loss: 0.8924 - accuracy: 0.51 - 22s 445ms/step - loss: 0.8854 - accuracy: 0.51 - 22s 437ms/step - loss: 0.8855 - accuracy: 0.51 - 22s 429ms/step - loss: 0.8831 - accuracy: 0.51 - 22s 421ms/step - loss: 0.8780 - accuracy: 0.51 - 22s 413ms/step - loss: 0.8749 - accuracy: 0.52 - 22s 406ms/step - loss: 0.8708 - accuracy: 0.52 - 22s 399ms/step - loss: 0.8687 - accuracy: 0.52 - 22s 392ms/step - loss: 0.8657 - accuracy: 0.52 - 22s 386ms/step - loss: 0.8651 - accuracy: 0.52 - 22s 379ms/step - loss: 0.8607 - accuracy: 0.52 - 22s 373ms/step - loss: 0.8573 - accuracy: 0.53 - 22s 367ms/step - loss: 0.8528 - accuracy: 0.53 - 22s 362ms/step - loss: 0.8486 - accuracy: 0.53 - 22s 356ms/step - loss: 0.8450 - accuracy: 0.53 - 22s 351ms/step - loss: 0.8433 - accuracy: 0.53 - 22s 345ms/step - loss: 0.8398 - accuracy: 0.54 - 22s 340ms/step - loss: 0.8364 - accuracy: 0.54 - 22s 336ms/step - loss: 0.8328 - accuracy: 0.54 - 22s 331ms/step - loss: 0.8309 - accuracy: 0.54 - 22s 326ms/step - loss: 0.8287 - accuracy: 0.54 - 22s 322ms/step - loss: 0.8281 - accuracy: 0.54 - 22s 317ms/step - loss: 0.8254 - accuracy: 0.54 - 22s 313ms/step - loss: 0.8226 - accuracy: 0.54 - 22s 309ms/step - loss: 0.8201 - accuracy: 0.54 - 22s 305ms/step - loss: 0.8176 - accuracy: 0.54 - 22s 301ms/step - loss: 0.8168 - accuracy: 0.55 - 22s 297ms/step - loss: 0.8132 - accuracy: 0.55 - 22s 294ms/step - loss: 0.8125 - accuracy: 0.55 - 22s 290ms/step - loss: 0.8090 - accuracy: 0.55 - 22s 287ms/step - loss: 0.8068 - accuracy: 0.55 - 22s 283ms/step - loss: 0.8055 - accuracy: 0.55 - 22s 280ms/step - loss: 0.8051 - accuracy: 0.55 - 22s 277ms/step - loss: 0.8047 - accuracy: 0.55 - 22s 274ms/step - loss: 0.8041 - accuracy: 0.55 - 22s 271ms/step - loss: 0.8027 - accuracy: 0.55 - 22s 268ms/step - loss: 0.8005 - accuracy: 0.55 - 23s 265ms/step - loss: 0.7986 - accuracy: 0.55 - 23s 262ms/step - loss: 0.7964 - accuracy: 0.55 - 23s 259ms/step - loss: 0.7959 - accuracy: 0.55 - 23s 256ms/step - loss: 0.7934 - accuracy: 0.56 - 23s 254ms/step - loss: 0.7917 - accuracy: 0.56 - 23s 251ms/step - loss: 0.7901 - accuracy: 0.56 - 23s 249ms/step - loss: 0.7882 - accuracy: 0.56 - 23s 246ms/step - loss: 0.7858 - accuracy: 0.56 - 23s 244ms/step - loss: 0.7840 - accuracy: 0.56 - 23s 241ms/step - loss: 0.7812 - accuracy: 0.56 - 23s 239ms/step - loss: 0.7810 - accuracy: 0.56 - 23s 237ms/step - loss: 0.7819 - accuracy: 0.56 - 23s 234ms/step - loss: 0.7800 - accuracy: 0.56 - 23s 232ms/step - loss: 0.7783 - accuracy: 0.56 - 23s 230ms/step - loss: 0.7776 - accuracy: 0.56 - 23s 228ms/step - loss: 0.7769 - accuracy: 0.56 - 23s 226ms/step - loss: 0.7769 - accuracy: 0.56 - 23s 224ms/step - loss: 0.7751 - accuracy: 0.57 - 23s 222ms/step - loss: 0.7730 - accuracy: 0.57 - 23s 220ms/step - loss: 0.7716 - accuracy: 0.57 - 23s 218ms/step - loss: 0.7692 - accuracy: 0.57 - 23s 216ms/step - loss: 0.7680 - accuracy: 0.57 - 23s 214ms/step - loss: 0.7676 - accuracy: 0.57 - 23s 212ms/step - loss: 0.7669 - accuracy: 0.57 - 23s 211ms/step - loss: 0.7664 - accuracy: 0.57 - 23s 209ms/step - loss: 0.7667 - accuracy: 0.57 - 23s 207ms/step - loss: 0.7645 - accuracy: 0.57 - 23s 205ms/step - loss: 0.7634 - accuracy: 0.57 - 23s 204ms/step - loss: 0.7621 - accuracy: 0.57 - 23s 202ms/step - loss: 0.7610 - accuracy: 0.57 - 23s 201ms/step - loss: 0.7594 - accuracy: 0.58 - 23s 199ms/step - loss: 0.7573 - accuracy: 0.58 - 23s 197ms/step - loss: 0.7566 - accuracy: 0.58 - 23s 196ms/step - loss: 0.7560 - accuracy: 0.58 - 23s 194ms/step - loss: 0.7546 - accuracy: 0.58 - 23s 193ms/step - loss: 0.7530 - accuracy: 0.58 - 23s 192ms/step - loss: 0.7517 - accuracy: 0.58 - 23s 190ms/step - loss: 0.7494 - accuracy: 0.58 - 23s 189ms/step - loss: 0.7484 - accuracy: 0.58 - 23s 187ms/step - loss: 0.7481 - accuracy: 0.58 - 23s 186ms/step - loss: 0.7479 - accuracy: 0.58 - 23s 185ms/step - loss: 0.7467 - accuracy: 0.58 - 23s 183ms/step - loss: 0.7461 - accuracy: 0.58 - 23s 182ms/step - loss: 0.7438 - accuracy: 0.59 - 23s 181ms/step - loss: 0.7436 - accuracy: 0.59 - 23s 180ms/step - loss: 0.7427 - accuracy: 0.59 - 23s 178ms/step - loss: 0.7415 - accuracy: 0.59 - 23s 177ms/step - loss: 0.7415 - accuracy: 0.59 - 23s 176ms/step - loss: 0.7408 - accuracy: 0.59 - 23s 175ms/step - loss: 0.7399 - accuracy: 0.59 - 23s 174ms/step - loss: 0.7388 - accuracy: 0.59 - 23s 173ms/step - loss: 0.7377 - accuracy: 0.59 - 23s 171ms/step - loss: 0.7364 - accuracy: 0.59 - 24s 170ms/step - loss: 0.7355 - accuracy: 0.59 - 24s 169ms/step - loss: 0.7343 - accuracy: 0.59 - 24s 168ms/step - loss: 0.7330 - accuracy: 0.59 - 24s 167ms/step - loss: 0.7320 - accuracy: 0.59 - 24s 166ms/step - loss: 0.7315 - accuracy: 0.59 - 24s 165ms/step - loss: 0.7299 - accuracy: 0.59 - 24s 164ms/step - loss: 0.7285 - accuracy: 0.59 - 24s 163ms/step - loss: 0.7274 - accuracy: 0.59 - 24s 162ms/step - loss: 0.7269 - accuracy: 0.60 - 24s 161ms/step - loss: 0.7258 - accuracy: 0.60 - 24s 160ms/step - loss: 0.7264 - accuracy: 0.60 - 24s 159ms/step - loss: 0.7251 - accuracy: 0.60 - 24s 158ms/step - loss: 0.7246 - accuracy: 0.60 - 24s 157ms/step - loss: 0.7236 - accuracy: 0.60 - 24s 156ms/step - loss: 0.7235 - accuracy: 0.60 - 24s 156ms/step - loss: 0.7219 - accuracy: 0.60 - 24s 155ms/step - loss: 0.7212 - accuracy: 0.60 - 24s 154ms/step - loss: 0.7209 - accuracy: 0.60 - 24s 153ms/step - loss: 0.7204 - accuracy: 0.60 - 24s 152ms/step - loss: 0.7195 - accuracy: 0.60 - 24s 151ms/step - loss: 0.7181 - accuracy: 0.60 - 24s 150ms/step - loss: 0.7172 - accuracy: 0.60 - 24s 150ms/step - loss: 0.7167 - accuracy: 0.60 - 24s 149ms/step - loss: 0.7156 - accuracy: 0.60 - 24s 148ms/step - loss: 0.7148 - accuracy: 0.60 - 24s 147ms/step - loss: 0.7148 - accuracy: 0.60 - 24s 146ms/step - loss: 0.7134 - accuracy: 0.60 - 24s 146ms/step - loss: 0.7132 - accuracy: 0.61 - 24s 145ms/step - loss: 0.7127 - accuracy: 0.61 - 24s 144ms/step - loss: 0.7122 - accuracy: 0.61 - 24s 143ms/step - loss: 0.7125 - accuracy: 0.61 - 24s 143ms/step - loss: 0.7119 - accuracy: 0.61 - 24s 142ms/step - loss: 0.7115 - accuracy: 0.61 - 24s 141ms/step - loss: 0.7101 - accuracy: 0.61 - 24s 140ms/step - loss: 0.7093 - accuracy: 0.61 - 24s 140ms/step - loss: 0.7095 - accuracy: 0.61 - 24s 139ms/step - loss: 0.7091 - accuracy: 0.61 - 24s 138ms/step - loss: 0.7086 - accuracy: 0.61 - 24s 138ms/step - loss: 0.7082 - accuracy: 0.61 - 24s 137ms/step - loss: 0.7072 - accuracy: 0.61 - 24s 136ms/step - loss: 0.7068 - accuracy: 0.61 - 24s 136ms/step - loss: 0.7061 - accuracy: 0.61 - 24s 135ms/step - loss: 0.7052 - accuracy: 0.61 - 24s 134ms/step - loss: 0.7044 - accuracy: 0.61 - 24s 134ms/step - loss: 0.7044 - accuracy: 0.61 - 24s 133ms/step - loss: 0.7042 - accuracy: 0.61 - 24s 133ms/step - loss: 0.7033 - accuracy: 0.61 - 24s 132ms/step - loss: 0.7028 - accuracy: 0.61 - 24s 131ms/step - loss: 0.7020 - accuracy: 0.61 - 24s 131ms/step - loss: 0.7012 - accuracy: 0.61 - 24s 130ms/step - loss: 0.7006 - accuracy: 0.61 - 24s 130ms/step - loss: 0.6997 - accuracy: 0.62 - 25s 129ms/step - loss: 0.6992 - accuracy: 0.62 - 25s 128ms/step - loss: 0.6982 - accuracy: 0.62 - 25s 128ms/step - loss: 0.6974 - accuracy: 0.62 - 25s 127ms/step - loss: 0.6964 - accuracy: 0.62 - 25s 127ms/step - loss: 0.6961 - accuracy: 0.62 - 25s 126ms/step - loss: 0.6952 - accuracy: 0.62 - 25s 126ms/step - loss: 0.6947 - accuracy: 0.62 - 25s 125ms/step - loss: 0.6941 - accuracy: 0.62 - 25s 125ms/step - loss: 0.6934 - accuracy: 0.62 - 25s 124ms/step - loss: 0.6927 - accuracy: 0.62 - 25s 123ms/step - loss: 0.6917 - accuracy: 0.62 - 25s 123ms/step - loss: 0.6914 - accuracy: 0.62 - 25s 122ms/step - loss: 0.6911 - accuracy: 0.62 - 25s 122ms/step - loss: 0.6904 - accuracy: 0.62 - 25s 121ms/step - loss: 0.6908 - accuracy: 0.62 - 25s 121ms/step - loss: 0.6895 - accuracy: 0.62 - 25s 120ms/step - loss: 0.6888 - accuracy: 0.62 - 25s 120ms/step - loss: 0.6877 - accuracy: 0.62 - 25s 119ms/step - loss: 0.6871 - accuracy: 0.62 - 25s 119ms/step - loss: 0.6861 - accuracy: 0.62 - 25s 119ms/step - loss: 0.6857 - accuracy: 0.62 - 25s 118ms/step - loss: 0.6847 - accuracy: 0.63 - 25s 118ms/step - loss: 0.6840 - accuracy: 0.63 - 25s 117ms/step - loss: 0.6834 - accuracy: 0.63 - 25s 117ms/step - loss: 0.6833 - accuracy: 0.63 - 25s 116ms/step - loss: 0.6828 - accuracy: 0.63 - 25s 116ms/step - loss: 0.6818 - accuracy: 0.63 - 25s 115ms/step - loss: 0.6806 - accuracy: 0.63 - 25s 115ms/step - loss: 0.6796 - accuracy: 0.63 - 25s 114ms/step - loss: 0.6796 - accuracy: 0.63 - 25s 114ms/step - loss: 0.6786 - accuracy: 0.63 - 25s 114ms/step - loss: 0.6779 - accuracy: 0.63 - 25s 113ms/step - loss: 0.6772 - accuracy: 0.63 - 25s 113ms/step - loss: 0.6768 - accuracy: 0.63 - 25s 112ms/step - loss: 0.6767 - accuracy: 0.63 - 25s 112ms/step - loss: 0.6759 - accuracy: 0.63 - 25s 112ms/step - loss: 0.6752 - accuracy: 0.63 - 25s 111ms/step - loss: 0.6745 - accuracy: 0.63 - 25s 111ms/step - loss: 0.6733 - accuracy: 0.63 - 25s 110ms/step - loss: 0.6727 - accuracy: 0.63 - 25s 110ms/step - loss: 0.6721 - accuracy: 0.63 - 25s 110ms/step - loss: 0.6717 - accuracy: 0.63 - 25s 109ms/step - loss: 0.6705 - accuracy: 0.64 - 25s 109ms/step - loss: 0.6700 - accuracy: 0.64 - 25s 108ms/step - loss: 0.6691 - accuracy: 0.64 - 25s 108ms/step - loss: 0.6686 - accuracy: 0.64 - 25s 108ms/step - loss: 0.6685 - accuracy: 0.64 - 25s 107ms/step - loss: 0.6680 - accuracy: 0.64 - 25s 107ms/step - loss: 0.6672 - accuracy: 0.64 - 25s 107ms/step - loss: 0.6664 - accuracy: 0.64 - 25s 106ms/step - loss: 0.6657 - accuracy: 0.64 - 25s 106ms/step - loss: 0.6646 - accuracy: 0.64 - 26s 105ms/step - loss: 0.6636 - accuracy: 0.64 - 26s 105ms/step - loss: 0.6632 - accuracy: 0.64 - 26s 105ms/step - loss: 0.6624 - accuracy: 0.64 - 26s 104ms/step - loss: 0.6624 - accuracy: 0.64 - 26s 104ms/step - loss: 0.6616 - accuracy: 0.64 - 26s 104ms/step - loss: 0.6607 - accuracy: 0.64 - 26s 103ms/step - loss: 0.6600 - accuracy: 0.64 - 26s 103ms/step - loss: 0.6593 - accuracy: 0.64 - 26s 103ms/step - loss: 0.6590 - accuracy: 0.64 - 26s 102ms/step - loss: 0.6580 - accuracy: 0.64 - 26s 102ms/step - loss: 0.6568 - accuracy: 0.65 - 26s 102ms/step - loss: 0.6561 - accuracy: 0.65 - 26s 101ms/step - loss: 0.6558 - accuracy: 0.65 - 26s 101ms/step - loss: 0.6553 - accuracy: 0.65 - 26s 101ms/step - loss: 0.6547 - accuracy: 0.65 - 26s 100ms/step - loss: 0.6541 - accuracy: 0.65 - 26s 100ms/step - loss: 0.6535 - accuracy: 0.65 - 26s 100ms/step - loss: 0.6528 - accuracy: 0.65 - 26s 99ms/step - loss: 0.6528 - accuracy: 0.6529 - 26s 99ms/step - loss: 0.6521 - accuracy: 0.653 - 26s 99ms/step - loss: 0.6511 - accuracy: 0.654 - 26s 99ms/step - loss: 0.6501 - accuracy: 0.654 - 26s 98ms/step - loss: 0.6494 - accuracy: 0.655 - 26s 98ms/step - loss: 0.6485 - accuracy: 0.655 - 26s 98ms/step - loss: 0.6478 - accuracy: 0.656 - 26s 97ms/step - loss: 0.6474 - accuracy: 0.656 - 26s 97ms/step - loss: 0.6469 - accuracy: 0.656 - 26s 97ms/step - loss: 0.6461 - accuracy: 0.657 - 26s 96ms/step - loss: 0.6452 - accuracy: 0.657 - 26s 96ms/step - loss: 0.6447 - accuracy: 0.658 - 26s 96ms/step - loss: 0.6446 - accuracy: 0.658 - 26s 96ms/step - loss: 0.6443 - accuracy: 0.658 - 26s 95ms/step - loss: 0.6438 - accuracy: 0.659 - 26s 95ms/step - loss: 0.6429 - accuracy: 0.659 - 26s 95ms/step - loss: 0.6426 - accuracy: 0.659 - 26s 95ms/step - loss: 0.6423 - accuracy: 0.660 - 26s 94ms/step - loss: 0.6415 - accuracy: 0.660 - 26s 94ms/step - loss: 0.6411 - accuracy: 0.660 - 26s 94ms/step - loss: 0.6405 - accuracy: 0.661 - 26s 93ms/step - loss: 0.6398 - accuracy: 0.661 - 26s 93ms/step - loss: 0.6394 - accuracy: 0.662 - 26s 93ms/step - loss: 0.6386 - accuracy: 0.663 - 26s 93ms/step - loss: 0.6387 - accuracy: 0.663 - 26s 92ms/step - loss: 0.6381 - accuracy: 0.663 - 26s 92ms/step - loss: 0.6375 - accuracy: 0.664 - 26s 92ms/step - loss: 0.6366 - accuracy: 0.664 - 26s 92ms/step - loss: 0.6360 - accuracy: 0.665 - 26s 91ms/step - loss: 0.6357 - accuracy: 0.665 - 26s 91ms/step - loss: 0.6353 - accuracy: 0.665 - 26s 91ms/step - loss: 0.6346 - accuracy: 0.665 - 26s 91ms/step - loss: 0.6340 - accuracy: 0.666 - 27s 90ms/step - loss: 0.6332 - accuracy: 0.666 - 27s 90ms/step - loss: 0.6331 - accuracy: 0.666 - 27s 90ms/step - loss: 0.6331 - accuracy: 0.666 - 27s 90ms/step - loss: 0.6328 - accuracy: 0.667 - 27s 90ms/step - loss: 0.6332 - accuracy: 0.667 - 27s 89ms/step - loss: 0.6327 - accuracy: 0.667 - 27s 89ms/step - loss: 0.6321 - accuracy: 0.667 - 27s 89ms/step - loss: 0.6321 - accuracy: 0.667 - 27s 89ms/step - loss: 0.6320 - accuracy: 0.667 - 27s 88ms/step - loss: 0.6314 - accuracy: 0.668 - 27s 88ms/step - loss: 0.6313 - accuracy: 0.668 - 27s 88ms/step - loss: 0.6306 - accuracy: 0.669 - 27s 88ms/step - loss: 0.6301 - accuracy: 0.669 - 27s 87ms/step - loss: 0.6293 - accuracy: 0.669 - 27s 87ms/step - loss: 0.6285 - accuracy: 0.670 - 27s 87ms/step - loss: 0.6283 - accuracy: 0.670 - 27s 87ms/step - loss: 0.6276 - accuracy: 0.670 - 27s 87ms/step - loss: 0.6269 - accuracy: 0.671 - 27s 86ms/step - loss: 0.6266 - accuracy: 0.671 - 27s 86ms/step - loss: 0.6260 - accuracy: 0.671 - 27s 86ms/step - loss: 0.6254 - accuracy: 0.671 - 27s 86ms/step - loss: 0.6249 - accuracy: 0.672 - 27s 86ms/step - loss: 0.6245 - accuracy: 0.672 - 27s 85ms/step - loss: 0.6241 - accuracy: 0.672 - 27s 85ms/step - loss: 0.6236 - accuracy: 0.673 - 27s 85ms/step - loss: 0.6230 - accuracy: 0.673 - 27s 85ms/step - loss: 0.6220 - accuracy: 0.674 - 27s 84ms/step - loss: 0.6214 - accuracy: 0.674 - 27s 84ms/step - loss: 0.6215 - accuracy: 0.674 - 27s 84ms/step - loss: 0.6210 - accuracy: 0.675 - 27s 84ms/step - loss: 0.6205 - accuracy: 0.675 - 27s 84ms/step - loss: 0.6197 - accuracy: 0.676 - 27s 83ms/step - loss: 0.6192 - accuracy: 0.676 - 27s 83ms/step - loss: 0.6185 - accuracy: 0.676 - 27s 83ms/step - loss: 0.6182 - accuracy: 0.677 - 27s 83ms/step - loss: 0.6174 - accuracy: 0.677 - 27s 83ms/step - loss: 0.6166 - accuracy: 0.678 - 27s 83ms/step - loss: 0.6165 - accuracy: 0.678 - 27s 82ms/step - loss: 0.6165 - accuracy: 0.678 - 27s 82ms/step - loss: 0.6159 - accuracy: 0.678 - 27s 82ms/step - loss: 0.6153 - accuracy: 0.679 - 27s 82ms/step - loss: 0.6148 - accuracy: 0.679 - 27s 82ms/step - loss: 0.6145 - accuracy: 0.679 - 27s 81ms/step - loss: 0.6139 - accuracy: 0.680 - 27s 81ms/step - loss: 0.6136 - accuracy: 0.680 - 27s 81ms/step - loss: 0.6133 - accuracy: 0.680 - 27s 81ms/step - loss: 0.6129 - accuracy: 0.680 - 27s 81ms/step - loss: 0.6123 - accuracy: 0.681 - 27s 81ms/step - loss: 0.6118 - accuracy: 0.681 - 27s 80ms/step - loss: 0.6111 - accuracy: 0.682 - 27s 80ms/step - loss: 0.6109 - accuracy: 0.682 - 28s 80ms/step - loss: 0.6108 - accuracy: 0.682 - 28s 80ms/step - loss: 0.6100 - accuracy: 0.682 - 28s 80ms/step - loss: 0.6097 - accuracy: 0.683 - 28s 79ms/step - loss: 0.6100 - accuracy: 0.683 - 28s 79ms/step - loss: 0.6094 - accuracy: 0.683 - 28s 79ms/step - loss: 0.6088 - accuracy: 0.683 - 28s 79ms/step - loss: 0.6083 - accuracy: 0.684 - 28s 79ms/step - loss: 0.6075 - accuracy: 0.684 - 28s 79ms/step - loss: 0.6069 - accuracy: 0.685 - 28s 78ms/step - loss: 0.6065 - accuracy: 0.685 - 28s 78ms/step - loss: 0.6059 - accuracy: 0.686 - 28s 78ms/step - loss: 0.6058 - accuracy: 0.686 - 28s 78ms/step - loss: 0.6053 - accuracy: 0.686 - 28s 78ms/step - loss: 0.6047 - accuracy: 0.686 - 28s 78ms/step - loss: 0.6040 - accuracy: 0.687 - 28s 77ms/step - loss: 0.6035 - accuracy: 0.687 - 28s 77ms/step - loss: 0.6026 - accuracy: 0.688 - 28s 77ms/step - loss: 0.6026 - accuracy: 0.688 - 28s 77ms/step - loss: 0.6022 - accuracy: 0.688 - 28s 77ms/step - loss: 0.6020 - accuracy: 0.688 - 28s 77ms/step - loss: 0.6016 - accuracy: 0.689 - 28s 77ms/step - loss: 0.6011 - accuracy: 0.689 - 28s 76ms/step - loss: 0.6009 - accuracy: 0.689 - 28s 76ms/step - loss: 0.6004 - accuracy: 0.689 - 28s 76ms/step - loss: 0.6001 - accuracy: 0.690 - 28s 76ms/step - loss: 0.5994 - accuracy: 0.690 - 28s 76ms/step - loss: 0.5988 - accuracy: 0.691 - 28s 76ms/step - loss: 0.5983 - accuracy: 0.691 - 28s 75ms/step - loss: 0.5978 - accuracy: 0.691 - 28s 75ms/step - loss: 0.5977 - accuracy: 0.691 - 28s 75ms/step - loss: 0.5974 - accuracy: 0.691 - 28s 75ms/step - loss: 0.5973 - accuracy: 0.692 - 28s 75ms/step - loss: 0.5967 - accuracy: 0.692 - 28s 75ms/step - loss: 0.5963 - accuracy: 0.692 - 28s 75ms/step - loss: 0.5959 - accuracy: 0.692 - 28s 74ms/step - loss: 0.5956 - accuracy: 0.693 - 28s 74ms/step - loss: 0.5950 - accuracy: 0.693 - 28s 74ms/step - loss: 0.5946 - accuracy: 0.693 - 28s 74ms/step - loss: 0.5943 - accuracy: 0.693 - 28s 74ms/step - loss: 0.5939 - accuracy: 0.694 - 28s 74ms/step - loss: 0.5935 - accuracy: 0.694 - 28s 74ms/step - loss: 0.5932 - accuracy: 0.694 - 28s 73ms/step - loss: 0.5931 - accuracy: 0.694 - 28s 73ms/step - loss: 0.5927 - accuracy: 0.695 - 28s 73ms/step - loss: 0.5920 - accuracy: 0.695 - 28s 73ms/step - loss: 0.5918 - accuracy: 0.695 - 28s 73ms/step - loss: 0.5911 - accuracy: 0.696 - 28s 73ms/step - loss: 0.5910 - accuracy: 0.696 - 28s 73ms/step - loss: 0.5907 - accuracy: 0.696 - 28s 72ms/step - loss: 0.5901 - accuracy: 0.696 - 28s 72ms/step - loss: 0.5896 - accuracy: 0.697 - 29s 72ms/step - loss: 0.5891 - accuracy: 0.697 - 29s 72ms/step - loss: 0.5888 - accuracy: 0.697 - 29s 72ms/step - loss: 0.5883 - accuracy: 0.697 - 29s 72ms/step - loss: 0.5882 - accuracy: 0.698 - 29s 72ms/step - loss: 0.5878 - accuracy: 0.698 - 29s 72ms/step - loss: 0.5874 - accuracy: 0.698 - 29s 71ms/step - loss: 0.5871 - accuracy: 0.698 - 29s 71ms/step - loss: 0.5868 - accuracy: 0.698 - 29s 71ms/step - loss: 0.5864 - accuracy: 0.698 - 29s 71ms/step - loss: 0.5860 - accuracy: 0.698 - 29s 71ms/step - loss: 0.5854 - accuracy: 0.699 - 29s 71ms/step - loss: 0.5849 - accuracy: 0.699 - 29s 71ms/step - loss: 0.5844 - accuracy: 0.699 - 29s 71ms/step - loss: 0.5839 - accuracy: 0.700 - 29s 70ms/step - loss: 0.5836 - accuracy: 0.700 - 29s 70ms/step - loss: 0.5839 - accuracy: 0.700 - 29s 70ms/step - loss: 0.5835 - accuracy: 0.700 - 29s 70ms/step - loss: 0.5833 - accuracy: 0.700 - 29s 70ms/step - loss: 0.5829 - accuracy: 0.700 - 29s 70ms/step - loss: 0.5826 - accuracy: 0.700 - 29s 70ms/step - loss: 0.5825 - accuracy: 0.700 - 29s 70ms/step - loss: 0.5821 - accuracy: 0.701 - 29s 69ms/step - loss: 0.5819 - accuracy: 0.701 - 29s 69ms/step - loss: 0.5816 - accuracy: 0.701 - 29s 69ms/step - loss: 0.5812 - accuracy: 0.701 - 29s 69ms/step - loss: 0.5808 - accuracy: 0.702 - 29s 69ms/step - loss: 0.5806 - accuracy: 0.702 - 29s 69ms/step - loss: 0.5803 - accuracy: 0.702 - 29s 69ms/step - loss: 0.5798 - accuracy: 0.702 - 29s 69ms/step - loss: 0.5795 - accuracy: 0.703 - 29s 68ms/step - loss: 0.5792 - accuracy: 0.703 - 29s 68ms/step - loss: 0.5794 - accuracy: 0.703 - 29s 68ms/step - loss: 0.5790 - accuracy: 0.703 - 29s 68ms/step - loss: 0.5787 - accuracy: 0.703 - 29s 68ms/step - loss: 0.5787 - accuracy: 0.703 - 29s 68ms/step - loss: 0.5784 - accuracy: 0.704 - 29s 68ms/step - loss: 0.5783 - accuracy: 0.704 - 29s 68ms/step - loss: 0.5778 - accuracy: 0.704 - 29s 68ms/step - loss: 0.5776 - accuracy: 0.704 - 29s 67ms/step - loss: 0.5774 - accuracy: 0.704 - 29s 67ms/step - loss: 0.5772 - accuracy: 0.704 - 29s 67ms/step - loss: 0.5769 - accuracy: 0.704 - 29s 67ms/step - loss: 0.5765 - accuracy: 0.705 - 29s 67ms/step - loss: 0.5764 - accuracy: 0.705 - 29s 67ms/step - loss: 0.5760 - accuracy: 0.705 - 29s 67ms/step - loss: 0.5757 - accuracy: 0.705 - 29s 67ms/step - loss: 0.5752 - accuracy: 0.706 - 29s 67ms/step - loss: 0.5748 - accuracy: 0.706 - 29s 66ms/step - loss: 0.5746 - accuracy: 0.706 - 29s 66ms/step - loss: 0.5743 - accuracy: 0.706 - 29s 66ms/step - loss: 0.5742 - accuracy: 0.706 - 30s 66ms/step - loss: 0.5739 - accuracy: 0.706 - 30s 66ms/step - loss: 0.5738 - accuracy: 0.706 - 30s 66ms/step - loss: 0.5733 - accuracy: 0.707 - 30s 66ms/step - loss: 0.5728 - accuracy: 0.707 - 30s 66ms/step - loss: 0.5725 - accuracy: 0.707 - 30s 66ms/step - loss: 0.5723 - accuracy: 0.708 - 30s 66ms/step - loss: 0.5720 - accuracy: 0.708 - 30s 65ms/step - loss: 0.5715 - accuracy: 0.708 - 30s 65ms/step - loss: 0.5709 - accuracy: 0.708 - 30s 65ms/step - loss: 0.5707 - accuracy: 0.708 - 30s 65ms/step - loss: 0.5706 - accuracy: 0.709 - 30s 65ms/step - loss: 0.5703 - accuracy: 0.709 - 30s 65ms/step - loss: 0.5699 - accuracy: 0.709 - 30s 65ms/step - loss: 0.5696 - accuracy: 0.709 - 30s 65ms/step - loss: 0.5691 - accuracy: 0.710 - 30s 65ms/step - loss: 0.5690 - accuracy: 0.710 - 30s 65ms/step - loss: 0.5687 - accuracy: 0.710 - 30s 64ms/step - loss: 0.5683 - accuracy: 0.710 - 30s 64ms/step - loss: 0.5679 - accuracy: 0.710 - 30s 64ms/step - loss: 0.5675 - accuracy: 0.711 - 30s 64ms/step - loss: 0.5671 - accuracy: 0.711 - 30s 64ms/step - loss: 0.5668 - accuracy: 0.711 - 30s 64ms/step - loss: 0.5664 - accuracy: 0.711 - 30s 64ms/step - loss: 0.5659 - accuracy: 0.712 - 30s 64ms/step - loss: 0.5657 - accuracy: 0.712 - 30s 64ms/step - loss: 0.5653 - accuracy: 0.712 - 30s 64ms/step - loss: 0.5650 - accuracy: 0.713 - 30s 63ms/step - loss: 0.5649 - accuracy: 0.713 - 30s 63ms/step - loss: 0.5647 - accuracy: 0.713 - 30s 63ms/step - loss: 0.5640 - accuracy: 0.713 - 30s 63ms/step - loss: 0.5637 - accuracy: 0.713 - 30s 63ms/step - loss: 0.5636 - accuracy: 0.713 - 30s 63ms/step - loss: 0.5635 - accuracy: 0.713 - 30s 63ms/step - loss: 0.5633 - accuracy: 0.714 - 30s 63ms/step - loss: 0.5631 - accuracy: 0.714 - 30s 63ms/step - loss: 0.5628 - accuracy: 0.714 - 30s 63ms/step - loss: 0.5625 - accuracy: 0.714 - 30s 63ms/step - loss: 0.5623 - accuracy: 0.714 - 30s 62ms/step - loss: 0.5623 - accuracy: 0.714 - 30s 62ms/step - loss: 0.5620 - accuracy: 0.715 - 30s 62ms/step - loss: 0.5616 - accuracy: 0.715 - 30s 62ms/step - loss: 0.5614 - accuracy: 0.715 - 30s 62ms/step - loss: 0.5611 - accuracy: 0.715 - 30s 62ms/step - loss: 0.5607 - accuracy: 0.716 - 30s 62ms/step - loss: 0.5603 - accuracy: 0.716 - 30s 62ms/step - loss: 0.5600 - accuracy: 0.716 - 30s 62ms/step - loss: 0.5594 - accuracy: 0.716 - 30s 62ms/step - loss: 0.5590 - accuracy: 0.717 - 30s 62ms/step - loss: 0.5586 - accuracy: 0.717 - 30s 62ms/step - loss: 0.5584 - accuracy: 0.717 - 30s 61ms/step - loss: 0.5581 - accuracy: 0.717 - 30s 61ms/step - loss: 0.5581 - accuracy: 0.717 - 31s 61ms/step - loss: 0.5576 - accuracy: 0.718 - 31s 61ms/step - loss: 0.5572 - accuracy: 0.718 - 31s 61ms/step - loss: 0.5570 - accuracy: 0.718 - 31s 61ms/step - loss: 0.5567 - accuracy: 0.718 - 31s 61ms/step - loss: 0.5564 - accuracy: 0.718 - 31s 61ms/step - loss: 0.5560 - accuracy: 0.718 - 31s 61ms/step - loss: 0.5557 - accuracy: 0.719 - 31s 61ms/step - loss: 0.5553 - accuracy: 0.719 - 31s 61ms/step - loss: 0.5548 - accuracy: 0.719 - 31s 61ms/step - loss: 0.5544 - accuracy: 0.719 - 31s 60ms/step - loss: 0.5541 - accuracy: 0.719 - 31s 60ms/step - loss: 0.5540 - accuracy: 0.720 - 31s 60ms/step - loss: 0.5537 - accuracy: 0.720 - 31s 60ms/step - loss: 0.5534 - accuracy: 0.720 - 31s 60ms/step - loss: 0.5530 - accuracy: 0.720 - 31s 60ms/step - loss: 0.5529 - accuracy: 0.720 - 31s 60ms/step - loss: 0.5524 - accuracy: 0.721 - 31s 60ms/step - loss: 0.5523 - accuracy: 0.721 - 31s 60ms/step - loss: 0.5520 - accuracy: 0.721 - 31s 60ms/step - loss: 0.5515 - accuracy: 0.721 - 31s 60ms/step - loss: 0.5513 - accuracy: 0.721 - 31s 60ms/step - loss: 0.5512 - accuracy: 0.721 - 31s 60ms/step - loss: 0.5509 - accuracy: 0.722 - 31s 59ms/step - loss: 0.5504 - accuracy: 0.722 - 31s 59ms/step - loss: 0.5501 - accuracy: 0.722 - 31s 59ms/step - loss: 0.5495 - accuracy: 0.722 - 31s 59ms/step - loss: 0.5489 - accuracy: 0.723 - 31s 59ms/step - loss: 0.5489 - accuracy: 0.723 - 31s 59ms/step - loss: 0.5486 - accuracy: 0.723 - 31s 59ms/step - loss: 0.5484 - accuracy: 0.723 - 31s 59ms/step - loss: 0.5484 - accuracy: 0.723 - 31s 59ms/step - loss: 0.5480 - accuracy: 0.723 - 31s 59ms/step - loss: 0.5478 - accuracy: 0.723 - 31s 59ms/step - loss: 0.5475 - accuracy: 0.724 - 31s 59ms/step - loss: 0.5473 - accuracy: 0.724 - 31s 59ms/step - loss: 0.5469 - accuracy: 0.724 - 31s 58ms/step - loss: 0.5467 - accuracy: 0.724 - 31s 58ms/step - loss: 0.5464 - accuracy: 0.724 - 31s 58ms/step - loss: 0.5462 - accuracy: 0.724 - 31s 58ms/step - loss: 0.5459 - accuracy: 0.724 - 31s 58ms/step - loss: 0.5453 - accuracy: 0.725 - 31s 58ms/step - loss: 0.5451 - accuracy: 0.725 - 31s 58ms/step - loss: 0.5446 - accuracy: 0.725 - 31s 58ms/step - loss: 0.5443 - accuracy: 0.725 - 31s 58ms/step - loss: 0.5440 - accuracy: 0.726 - 31s 58ms/step - loss: 0.5436 - accuracy: 0.726 - 31s 58ms/step - loss: 0.5436 - accuracy: 0.726 - 31s 58ms/step - loss: 0.5433 - accuracy: 0.726 - 31s 58ms/step - loss: 0.5429 - accuracy: 0.726 - 31s 58ms/step - loss: 0.5426 - accuracy: 0.726 - 32s 58ms/step - loss: 0.5425 - accuracy: 0.726 - 32s 57ms/step - loss: 0.5421 - accuracy: 0.727 - 32s 57ms/step - loss: 0.5418 - accuracy: 0.727 - 32s 57ms/step - loss: 0.5413 - accuracy: 0.727 - 32s 57ms/step - loss: 0.5409 - accuracy: 0.727 - 32s 57ms/step - loss: 0.5408 - accuracy: 0.727 - 32s 57ms/step - loss: 0.5405 - accuracy: 0.728 - 32s 57ms/step - loss: 0.5404 - accuracy: 0.728 - 32s 57ms/step - loss: 0.5400 - accuracy: 0.728 - 32s 57ms/step - loss: 0.5399 - accuracy: 0.728 - 32s 57ms/step - loss: 0.5396 - accuracy: 0.728 - 32s 57ms/step - loss: 0.5393 - accuracy: 0.728 - 32s 57ms/step - loss: 0.5390 - accuracy: 0.729 - 32s 57ms/step - loss: 0.5389 - accuracy: 0.728 - 32s 57ms/step - loss: 0.5388 - accuracy: 0.729 - 32s 57ms/step - loss: 0.5385 - accuracy: 0.729 - 32s 56ms/step - loss: 0.5383 - accuracy: 0.729 - 32s 56ms/step - loss: 0.5381 - accuracy: 0.729 - 32s 56ms/step - loss: 0.5378 - accuracy: 0.729 - 32s 56ms/step - loss: 0.5374 - accuracy: 0.729 - 32s 56ms/step - loss: 0.5371 - accuracy: 0.729 - 32s 56ms/step - loss: 0.5371 - accuracy: 0.730 - 32s 56ms/step - loss: 0.5371 - accuracy: 0.730 - 32s 56ms/step - loss: 0.5369 - accuracy: 0.730 - 32s 56ms/step - loss: 0.5371 - accuracy: 0.730 - 32s 56ms/step - loss: 0.5370 - accuracy: 0.730 - 32s 56ms/step - loss: 0.5369 - accuracy: 0.730 - 32s 56ms/step - loss: 0.5368 - accuracy: 0.730 - 32s 56ms/step - loss: 0.5365 - accuracy: 0.730 - 32s 56ms/step - loss: 0.5363 - accuracy: 0.730 - 32s 56ms/step - loss: 0.5361 - accuracy: 0.730 - 32s 55ms/step - loss: 0.5359 - accuracy: 0.730 - 32s 55ms/step - loss: 0.5356 - accuracy: 0.731 - 32s 55ms/step - loss: 0.5352 - accuracy: 0.731 - 32s 55ms/step - loss: 0.5351 - accuracy: 0.731 - 32s 55ms/step - loss: 0.5349 - accuracy: 0.731 - 32s 55ms/step - loss: 0.5346 - accuracy: 0.731 - 32s 55ms/step - loss: 0.5343 - accuracy: 0.732 - 32s 55ms/step - loss: 0.5341 - accuracy: 0.732 - 32s 55ms/step - loss: 0.5338 - accuracy: 0.732 - 32s 55ms/step - loss: 0.5335 - accuracy: 0.732 - 32s 55ms/step - loss: 0.5331 - accuracy: 0.732 - 32s 55ms/step - loss: 0.5330 - accuracy: 0.732 - 32s 55ms/step - loss: 0.5331 - accuracy: 0.732 - 32s 55ms/step - loss: 0.5328 - accuracy: 0.733 - 32s 55ms/step - loss: 0.5327 - accuracy: 0.733 - 32s 55ms/step - loss: 0.5323 - accuracy: 0.733 - 32s 54ms/step - loss: 0.5322 - accuracy: 0.733 - 32s 54ms/step - loss: 0.5320 - accuracy: 0.733 - 32s 54ms/step - loss: 0.5320 - accuracy: 0.733 - 32s 54ms/step - loss: 0.5316 - accuracy: 0.733 - 32s 54ms/step - loss: 0.5313 - accuracy: 0.734 - 32s 54ms/step - loss: 0.5310 - accuracy: 0.734 - 33s 54ms/step - loss: 0.5308 - accuracy: 0.734 - 33s 54ms/step - loss: 0.5306 - accuracy: 0.734 - 33s 54ms/step - loss: 0.5302 - accuracy: 0.734 - 33s 54ms/step - loss: 0.5300 - accuracy: 0.734 - 33s 54ms/step - loss: 0.5298 - accuracy: 0.734 - 33s 54ms/step - loss: 0.5297 - accuracy: 0.735 - 33s 54ms/step - loss: 0.5296 - accuracy: 0.735 - 33s 54ms/step - loss: 0.5294 - accuracy: 0.735 - 33s 54ms/step - loss: 0.5293 - accuracy: 0.735 - 33s 54ms/step - loss: 0.5292 - accuracy: 0.735 - 33s 54ms/step - loss: 0.5289 - accuracy: 0.735 - 33s 53ms/step - loss: 0.5287 - accuracy: 0.735 - 33s 53ms/step - loss: 0.5285 - accuracy: 0.735 - 33s 53ms/step - loss: 0.5284 - accuracy: 0.735 - 33s 53ms/step - loss: 0.5282 - accuracy: 0.736 - 33s 53ms/step - loss: 0.5280 - accuracy: 0.736 - 33s 53ms/step - loss: 0.5279 - accuracy: 0.736 - 33s 53ms/step - loss: 0.5276 - accuracy: 0.736 - 33s 53ms/step - loss: 0.5275 - accuracy: 0.736 - 33s 53ms/step - loss: 0.5274 - accuracy: 0.736 - 33s 53ms/step - loss: 0.5272 - accuracy: 0.736 - 33s 53ms/step - loss: 0.5271 - accuracy: 0.736 - 33s 53ms/step - loss: 0.5269 - accuracy: 0.736 - 33s 53ms/step - loss: 0.5267 - accuracy: 0.736 - 33s 53ms/step - loss: 0.5266 - accuracy: 0.736 - 33s 53ms/step - loss: 0.5266 - accuracy: 0.737 - 33s 53ms/step - loss: 0.5263 - accuracy: 0.737 - 33s 53ms/step - loss: 0.5262 - accuracy: 0.737 - 33s 52ms/step - loss: 0.5261 - accuracy: 0.737 - 33s 52ms/step - loss: 0.5259 - accuracy: 0.737 - 33s 52ms/step - loss: 0.5255 - accuracy: 0.737 - 33s 52ms/step - loss: 0.5254 - accuracy: 0.737 - 33s 52ms/step - loss: 0.5252 - accuracy: 0.737 - 33s 52ms/step - loss: 0.5250 - accuracy: 0.738 - 33s 52ms/step - loss: 0.5246 - accuracy: 0.738 - 33s 52ms/step - loss: 0.5245 - accuracy: 0.738 - 33s 52ms/step - loss: 0.5243 - accuracy: 0.738 - 33s 52ms/step - loss: 0.5239 - accuracy: 0.738 - 33s 52ms/step - loss: 0.5236 - accuracy: 0.738 - 33s 52ms/step - loss: 0.5234 - accuracy: 0.739 - 33s 52ms/step - loss: 0.5232 - accuracy: 0.739 - 33s 52ms/step - loss: 0.5230 - accuracy: 0.739 - 33s 52ms/step - loss: 0.5229 - accuracy: 0.739 - 33s 52ms/step - loss: 0.5227 - accuracy: 0.739 - 33s 52ms/step - loss: 0.5223 - accuracy: 0.739 - 33s 52ms/step - loss: 0.5221 - accuracy: 0.739 - 33s 52ms/step - loss: 0.5218 - accuracy: 0.740 - 33s 51ms/step - loss: 0.5215 - accuracy: 0.740 - 33s 51ms/step - loss: 0.5212 - accuracy: 0.740 - 33s 51ms/step - loss: 0.5209 - accuracy: 0.740 - 33s 51ms/step - loss: 0.5207 - accuracy: 0.740 - 33s 51ms/step - loss: 0.5204 - accuracy: 0.740 - 33s 51ms/step - loss: 0.5201 - accuracy: 0.740 - 33s 51ms/step - loss: 0.5199 - accuracy: 0.741 - 33s 51ms/step - loss: 0.5196 - accuracy: 0.741 - 33s 51ms/step - loss: 0.5193 - accuracy: 0.741 - 34s 51ms/step - loss: 0.5191 - accuracy: 0.741 - 34s 51ms/step - loss: 0.5188 - accuracy: 0.741 - 34s 51ms/step - loss: 0.5187 - accuracy: 0.741 - 34s 51ms/step - loss: 0.5185 - accuracy: 0.742 - 34s 51ms/step - loss: 0.5183 - accuracy: 0.742 - 34s 51ms/step - loss: 0.5181 - accuracy: 0.742 - 34s 51ms/step - loss: 0.5180 - accuracy: 0.742 - 34s 51ms/step - loss: 0.5177 - accuracy: 0.742 - 34s 51ms/step - loss: 0.5174 - accuracy: 0.742 - 34s 51ms/step - loss: 0.5171 - accuracy: 0.742 - 34s 50ms/step - loss: 0.5169 - accuracy: 0.742 - 34s 50ms/step - loss: 0.5166 - accuracy: 0.743 - 34s 50ms/step - loss: 0.5165 - accuracy: 0.743 - 34s 50ms/step - loss: 0.5163 - accuracy: 0.743 - 34s 50ms/step - loss: 0.5160 - accuracy: 0.743 - 34s 50ms/step - loss: 0.5160 - accuracy: 0.743 - 34s 50ms/step - loss: 0.5156 - accuracy: 0.743 - 34s 50ms/step - loss: 0.5155 - accuracy: 0.743 - 34s 50ms/step - loss: 0.5154 - accuracy: 0.743 - 34s 50ms/step - loss: 0.5154 - accuracy: 0.743 - 34s 50ms/step - loss: 0.5151 - accuracy: 0.743 - 34s 50ms/step - loss: 0.5149 - accuracy: 0.744 - 34s 50ms/step - loss: 0.5146 - accuracy: 0.744 - 34s 50ms/step - loss: 0.5144 - accuracy: 0.744 - 34s 50ms/step - loss: 0.5141 - accuracy: 0.744 - 34s 50ms/step - loss: 0.5139 - accuracy: 0.744 - 34s 50ms/step - loss: 0.5137 - accuracy: 0.744 - 34s 50ms/step - loss: 0.5135 - accuracy: 0.744 - 34s 50ms/step - loss: 0.5134 - accuracy: 0.744 - 34s 50ms/step - loss: 0.5132 - accuracy: 0.745 - 34s 50ms/step - loss: 0.5131 - accuracy: 0.745 - 34s 49ms/step - loss: 0.5128 - accuracy: 0.745 - 34s 49ms/step - loss: 0.5125 - accuracy: 0.745 - 34s 49ms/step - loss: 0.5124 - accuracy: 0.745 - 34s 49ms/step - loss: 0.5123 - accuracy: 0.745 - 34s 49ms/step - loss: 0.5121 - accuracy: 0.745 - 34s 49ms/step - loss: 0.5119 - accuracy: 0.745 - 34s 49ms/step - loss: 0.5117 - accuracy: 0.745 - 34s 49ms/step - loss: 0.5114 - accuracy: 0.746 - 34s 49ms/step - loss: 0.5113 - accuracy: 0.746 - 34s 49ms/step - loss: 0.5112 - accuracy: 0.746 - 38s 54ms/step - loss: 0.5112 - accuracy: 0.7462 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "697/697 [==============================] ETA: 14:36 - loss: 0.3379 - accuracy: 0.843 - ETA: 2:47 - loss: 0.2955 - accuracy: 0.871 - ETA: 1:28 - loss: 0.3047 - accuracy: 0.86 - ETA: 1:03 - loss: 0.2907 - accuracy: 0.87 - ETA: 48s - loss: 0.2815 - accuracy: 0.8833 - ETA: 39s - loss: 0.2767 - accuracy: 0.881 - ETA: 30s - loss: 0.2646 - accuracy: 0.884 - ETA: 23s - loss: 0.2752 - accuracy: 0.881 - ETA: 19s - loss: 0.2749 - accuracy: 0.881 - ETA: 15s - loss: 0.2740 - accuracy: 0.882 - ETA: 12s - loss: 0.2692 - accuracy: 0.885 - ETA: 11s - loss: 0.2727 - accuracy: 0.884 - ETA: 9s - loss: 0.2725 - accuracy: 0.884 - ETA: 7s - loss: 0.2747 - accuracy: 0.88 - ETA: 6s - loss: 0.2772 - accuracy: 0.88 - ETA: 5s - loss: 0.2789 - accuracy: 0.88 - ETA: 4s - loss: 0.2831 - accuracy: 0.87 - ETA: 3s - loss: 0.2811 - accuracy: 0.87 - ETA: 3s - loss: 0.2822 - accuracy: 0.87 - ETA: 2s - loss: 0.2800 - accuracy: 0.87 - ETA: 1s - loss: 0.2822 - accuracy: 0.87 - ETA: 1s - loss: 0.2853 - accuracy: 0.87 - ETA: 0s - loss: 0.2859 - accuracy: 0.87 - 25s 36ms/step - loss: 0.2941 - accuracy: 0.8691 - val_loss: 0.3703 - val_accuracy: 0.8346\n",
      "Epoch 3/3\n",
      "697/697 [==============================] ETA: 14:28 - loss: 0.1264 - accuracy: 0.953 - ETA: 3:29 - loss: 0.1665 - accuracy: 0.933 - ETA: 1:55 - loss: 0.1941 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2003 - accuracy: 0.90 - ETA: 48s - loss: 0.1958 - accuracy: 0.9156 - ETA: 38s - loss: 0.1954 - accuracy: 0.917 - ETA: 31s - loss: 0.1984 - accuracy: 0.915 - ETA: 24s - loss: 0.1971 - accuracy: 0.915 - ETA: 21s - loss: 0.1957 - accuracy: 0.917 - ETA: 18s - loss: 0.1931 - accuracy: 0.919 - ETA: 14s - loss: 0.1942 - accuracy: 0.918 - ETA: 12s - loss: 0.1924 - accuracy: 0.921 - ETA: 10s - loss: 0.1925 - accuracy: 0.920 - ETA: 8s - loss: 0.1933 - accuracy: 0.920 - ETA: 7s - loss: 0.1919 - accuracy: 0.92 - ETA: 6s - loss: 0.1910 - accuracy: 0.92 - ETA: 5s - loss: 0.1910 - accuracy: 0.92 - ETA: 4s - loss: 0.1901 - accuracy: 0.92 - ETA: 3s - loss: 0.1937 - accuracy: 0.92 - ETA: 2s - loss: 0.1948 - accuracy: 0.91 - ETA: 1s - loss: 0.1966 - accuracy: 0.91 - ETA: 1s - loss: 0.1963 - accuracy: 0.91 - ETA: 0s - loss: 0.1994 - accuracy: 0.91 - ETA: 0s - loss: 0.1984 - accuracy: 0.91 - 25s 36ms/step - loss: 0.2206 - accuracy: 0.9037 - val_loss: 0.3815 - val_accuracy: 0.8444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x225471c7c08>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, epochs=3, validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================].3248 - accuracy: 0.85 - 2s 899ms/step - loss: 0.3078 - accuracy: 0.859 - 2s 607ms/step - loss: 0.3115 - accuracy: 0.859 - 2s 460ms/step - loss: 0.3008 - accuracy: 0.867 - 2s 373ms/step - loss: 0.3021 - accuracy: 0.871 - 2s 314ms/step - loss: 0.3155 - accuracy: 0.869 - 2s 273ms/step - loss: 0.3252 - accuracy: 0.868 - 2s 242ms/step - loss: 0.3186 - accuracy: 0.863 - 2s 218ms/step - loss: 0.3238 - accuracy: 0.855 - 2s 198ms/step - loss: 0.3300 - accuracy: 0.854 - 2s 183ms/step - loss: 0.3504 - accuracy: 0.846 - 2s 170ms/step - loss: 0.3440 - accuracy: 0.849 - 2s 158ms/step - loss: 0.3445 - accuracy: 0.849 - 2s 149ms/step - loss: 0.3574 - accuracy: 0.848 - 2s 140ms/step - loss: 0.3523 - accuracy: 0.851 - 2s 133ms/step - loss: 0.3526 - accuracy: 0.853 - 2s 127ms/step - loss: 0.3504 - accuracy: 0.852 - 2s 121ms/step - loss: 0.3498 - accuracy: 0.849 - 2s 116ms/step - loss: 0.3457 - accuracy: 0.851 - 2s 111ms/step - loss: 0.3555 - accuracy: 0.847 - 2s 107ms/step - loss: 0.3518 - accuracy: 0.848 - 2s 103ms/step - loss: 0.3463 - accuracy: 0.849 - 2s 100ms/step - loss: 0.3489 - accuracy: 0.849 - 2s 97ms/step - loss: 0.3533 - accuracy: 0.847 - 2s 94ms/step - loss: 0.3552 - accuracy: 0.84 - 2s 91ms/step - loss: 0.3604 - accuracy: 0.84 - 2s 88ms/step - loss: 0.3625 - accuracy: 0.84 - 2s 86ms/step - loss: 0.3626 - accuracy: 0.84 - 2s 84ms/step - loss: 0.3659 - accuracy: 0.84 - 2s 82ms/step - loss: 0.3675 - accuracy: 0.84 - 2s 80ms/step - loss: 0.3649 - accuracy: 0.84 - 3s 78ms/step - loss: 0.3637 - accuracy: 0.84 - 3s 77ms/step - loss: 0.3609 - accuracy: 0.84 - 3s 75ms/step - loss: 0.3585 - accuracy: 0.84 - 3s 74ms/step - loss: 0.3587 - accuracy: 0.84 - 3s 72ms/step - loss: 0.3575 - accuracy: 0.84 - 3s 71ms/step - loss: 0.3601 - accuracy: 0.84 - 3s 70ms/step - loss: 0.3613 - accuracy: 0.84 - 3s 69ms/step - loss: 0.3611 - accuracy: 0.84 - 3s 67ms/step - loss: 0.3610 - accuracy: 0.84 - 3s 66ms/step - loss: 0.3598 - accuracy: 0.84 - 3s 65ms/step - loss: 0.3593 - accuracy: 0.84 - 3s 64ms/step - loss: 0.3620 - accuracy: 0.84 - 3s 64ms/step - loss: 0.3653 - accuracy: 0.84 - 3s 63ms/step - loss: 0.3633 - accuracy: 0.84 - 3s 62ms/step - loss: 0.3650 - accuracy: 0.84 - 3s 61ms/step - loss: 0.3668 - accuracy: 0.84 - 3s 60ms/step - loss: 0.3675 - accuracy: 0.84 - 3s 59ms/step - loss: 0.3652 - accuracy: 0.84 - 3s 59ms/step - loss: 0.3641 - accuracy: 0.84 - 3s 58ms/step - loss: 0.3637 - accuracy: 0.84 - 3s 57ms/step - loss: 0.3631 - accuracy: 0.84 - 3s 57ms/step - loss: 0.3607 - accuracy: 0.84 - 3s 56ms/step - loss: 0.3592 - accuracy: 0.85 - 3s 56ms/step - loss: 0.3591 - accuracy: 0.85 - 3s 55ms/step - loss: 0.3586 - accuracy: 0.84 - 3s 55ms/step - loss: 0.3607 - accuracy: 0.84 - 3s 54ms/step - loss: 0.3619 - accuracy: 0.84 - 3s 53ms/step - loss: 0.3603 - accuracy: 0.84 - 3s 53ms/step - loss: 0.3630 - accuracy: 0.84 - 3s 52ms/step - loss: 0.3658 - accuracy: 0.84 - 3s 52ms/step - loss: 0.3636 - accuracy: 0.84 - 3s 51ms/step - loss: 0.3611 - accuracy: 0.84 - 3s 51ms/step - loss: 0.3598 - accuracy: 0.84 - 3s 51ms/step - loss: 0.3591 - accuracy: 0.84 - 3s 50ms/step - loss: 0.3640 - accuracy: 0.84 - 3s 50ms/step - loss: 0.3653 - accuracy: 0.84 - 3s 50ms/step - loss: 0.3664 - accuracy: 0.84 - 3s 49ms/step - loss: 0.3677 - accuracy: 0.84 - 3s 49ms/step - loss: 0.3676 - accuracy: 0.84 - 3s 48ms/step - loss: 0.3689 - accuracy: 0.84 - 3s 48ms/step - loss: 0.3696 - accuracy: 0.84 - 3s 48ms/step - loss: 0.3706 - accuracy: 0.84 - 4s 47ms/step - loss: 0.3718 - accuracy: 0.84 - 4s 47ms/step - loss: 0.3759 - accuracy: 0.84 - 4s 47ms/step - loss: 0.3749 - accuracy: 0.84 - 4s 46ms/step - loss: 0.3753 - accuracy: 0.84 - 4s 46ms/step - loss: 0.3774 - accuracy: 0.84 - 4s 46ms/step - loss: 0.3815 - accuracy: 0.84 - 4s 46ms/step - loss: 0.3815 - accuracy: 0.8444\n",
      "\n",
      "Eval loss: 0.382, Eval accuracy: 0.844\n"
     ]
    }
   ],
   "source": [
    "eval_loss, eval_acc = model.evaluate(test_data)\n",
    "\n",
    "print('\\nEval loss: {:.3f}, Eval accuracy: {:.3f}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
